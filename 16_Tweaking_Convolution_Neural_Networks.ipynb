{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "16. Tweaking Convolution Neural Networks.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMIMQH0hZVDR71Bf4BOdSHO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/raj-vijay/dl/blob/master/16_Tweaking_Convolution_Neural_Networks.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TW9wLOESptHM",
        "colab_type": "text"
      },
      "source": [
        "**Convolution Neural Network**\n",
        "\n",
        "In deep learning, a convolutional neural network (CNN, or ConvNet) is a class of deep neural networks, most commonly applied to analyzing visual imagery.\n",
        "\n",
        "They are also known as shift invariant or space invariant artificial neural networks (SIANN), based on their shared-weights architecture and translation invariance characteristics.\n",
        "\n",
        "They have applications in image and video recognition, recommender systems, image classification, medical image analysis, natural language processing, and financial time series."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KAezBe6GqCgp",
        "colab_type": "text"
      },
      "source": [
        "CNNs are regularized versions of multilayer perceptrons. Multilayer perceptrons usually mean fully connected networks, that is, each neuron in one layer is connected to all neurons in the next layer. \n",
        "\n",
        "The \"fully-connectedness\" of these networks makes them prone to overfitting data. Typical ways of regularization include adding some form of magnitude measurement of weights to the loss function. \n",
        "\n",
        "CNNs take a different approach towards regularization: they take advantage of the hierarchical pattern in data and assemble more complex patterns using smaller and simpler patterns. Therefore, on the scale of connectedness and complexity, CNNs are on the lower extreme.\n",
        "\n",
        "Convolutional networks were inspired by biological processes in that the connectivity pattern between neurons resembles the organization of the animal visual cortex. \n",
        "\n",
        "Individual cortical neurons respond to stimuli only in a restricted region of the visual field known as the receptive field. The receptive fields of different neurons partially overlap such that they cover the entire visual field.\n",
        " \n",
        "CNNs use relatively little pre-processing compared to other image classification algorithms. This means that the network learns the filters that in traditional algorithms were hand-engineered. This independence from prior knowledge and human effort in feature design is a major advantage. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dDKsiZoPqWVm",
        "colab_type": "text"
      },
      "source": [
        "The name “convolutional neural network” indicates that the network employs a mathematical operation called convolution. Convolution is a specialized kind of linear operation. Convolutional networks are simply neural networks that use convolution in place of general matrix multiplication in at least one of their layers."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PVk-V4bqt78F",
        "colab_type": "text"
      },
      "source": [
        "Source: https://en.wikipedia.org/wiki/Convolutional_neural_network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QTyK-diFJtBa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import fundamental libraries used for the tensorflow\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0CD2Yc08KgPM",
        "colab_type": "code",
        "outputId": "007096e2-9718-4061-a97e-6b7cc8c37fb8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "# Load the Fashion MNIST Data from TensorFlow Keras\n",
        "fashion_mnist = tf.keras.datasets.fashion_mnist\n",
        "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "32768/29515 [=================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26427392/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "8192/5148 [===============================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4423680/4422102 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "02aSFg43LVRz",
        "colab_type": "code",
        "outputId": "b85834a4-cf67-4f68-a1c9-070ee9f5e15b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# Shape of data\n",
        "print(\"Train Images: \", train_images.shape)\n",
        "print(\"Test Images: \", test_images.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train Images:  (60000, 28, 28)\n",
            "Test Images:  (10000, 28, 28)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MZkrm9kryYId",
        "colab_type": "code",
        "outputId": "83826e11-857e-470d-bc08-24a0c6859303",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# Reshape input data from (28, 28) to (28, 28, 1)\n",
        "w, h = 28, 28\n",
        "train_images = train_images.reshape(train_images.shape[0], w, h, 1)\n",
        "test_images = test_images.reshape(test_images.shape[0], w, h, 1)\n",
        "\n",
        "# One-hot encode the labels\n",
        "train_labels = tf.keras.utils.to_categorical(train_labels, 10)\n",
        "test_labels = tf.keras.utils.to_categorical(test_labels, 10)\n",
        "\n",
        "# Shape of data\n",
        "print(\"Reshaped Train Images: \", train_images.shape)\n",
        "print(\"Reshaped Test Images: \", test_images.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reshaped Train Images:  (60000, 28, 28, 1)\n",
            "Reshaped Test Images:  (10000, 28, 28, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ZZjnqmauxyL",
        "colab_type": "text"
      },
      "source": [
        "**Convolutional network for image classification**\n",
        "\n",
        "Convolutional networks for classification are constructed from a sequence of convolutional layers (for image processing) and fully connected (Dense) layers (for readout). \n",
        "\n",
        "Here, we construct a small convolutional network for classification of the data from the fashion dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QYbM4ZyFu-6e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import the necessary components from Keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Conv2D, Flatten\n",
        "\n",
        "# Initialize the model object\n",
        "model = Sequential()\n",
        "\n",
        "# Add a convolutional layer\n",
        "model.add(Conv2D(100, kernel_size=3, activation='relu', \n",
        "               input_shape=(28, 28, 1)))\n",
        "\n",
        "# Flatten the output of the convolutional layer\n",
        "model.add(Flatten())\n",
        "# Add an output layer for the 3 categories\n",
        "model.add(Dense(10, activation='softmax'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jk2TFn-5vz8c",
        "colab_type": "text"
      },
      "source": [
        "**Training a CNN to classify clothing types**\n",
        "\n",
        "Before training a neural network it needs to be compiled with the right cost function, using the right optimizer. \n",
        "\n",
        "During compilation, we also define metrics that the network calculates and reports in every epoch. \n",
        "\n",
        "Model fitting requires a training data set, together with the training labels to the network."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G0WeKK0sv9CJ",
        "colab_type": "code",
        "outputId": "13c19994-7fc6-4ff0-9106-a7ec5a2b2760",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "# Compile the model \n",
        "model.compile(optimizer='adam', \n",
        "              loss='categorical_crossentropy', \n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Fit the model on a training set\n",
        "model.fit(train_images, train_labels, \n",
        "          validation_split=0.2, \n",
        "          epochs=3, batch_size=10)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 48000 samples, validate on 12000 samples\n",
            "Epoch 1/3\n",
            "48000/48000 [==============================] - 95s 2ms/step - loss: 1.1067 - accuracy: 0.8329 - val_loss: 0.4056 - val_accuracy: 0.8547\n",
            "Epoch 2/3\n",
            "48000/48000 [==============================] - 98s 2ms/step - loss: 0.3595 - accuracy: 0.8736 - val_loss: 0.4447 - val_accuracy: 0.8611\n",
            "Epoch 3/3\n",
            "48000/48000 [==============================] - 96s 2ms/step - loss: 0.3045 - accuracy: 0.8907 - val_loss: 0.4370 - val_accuracy: 0.8565\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.callbacks.History at 0x7f1626a0dc50>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2m57eNEK0CBM",
        "colab_type": "text"
      },
      "source": [
        "**Evaluating a CNN with test data**\n",
        "\n",
        "To evaluate a trained neural network, provide a separate testing data set of labeled images."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UK_GCeW-0Il3",
        "colab_type": "code",
        "outputId": "1afd2650-f154-4ea6-d429-231307d8b432",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# Evaluate the model on separate test data\n",
        "model.evaluate(test_images, test_labels, batch_size=10)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 3s 291us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.4561278997566551, 0.8478000164031982]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SEvlJ1fg193A",
        "colab_type": "text"
      },
      "source": [
        "**Add padding to a CNN**\n",
        "\n",
        "Padding allows a convolutional layer to retain the resolution of the input into this layer. \n",
        "\n",
        "This is done by adding zeros around the edges of the input image, so that the convolution kernel can overlap with the pixels on the edge of the image."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MdF6xTXg2FOk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Initialize the model\n",
        "model1 = Sequential()\n",
        "\n",
        "# Add the convolutional layer\n",
        "model1.add(Conv2D(100, kernel_size=3, activation='relu', \n",
        "                 input_shape=(28, 28, 1), \n",
        "                 padding='same'))\n",
        "\n",
        "# Feed into output layer\n",
        "model1.add(Flatten())\n",
        "model1.add(Dense(10, activation='softmax'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3cbmsP5s5Ixc",
        "colab_type": "code",
        "outputId": "f535c587-ac2d-4af5-a36e-46d04b7ae3c4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "# Compile the model \n",
        "model1.compile(optimizer='adam', \n",
        "              loss='categorical_crossentropy', \n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Fit the model on a training set\n",
        "model1.fit(train_images, train_labels, \n",
        "          validation_split=0.2, \n",
        "          epochs=3, batch_size=10)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 48000 samples, validate on 12000 samples\n",
            "Epoch 1/3\n",
            "48000/48000 [==============================] - 107s 2ms/step - loss: 1.1928 - accuracy: 0.8392 - val_loss: 0.4262 - val_accuracy: 0.8502\n",
            "Epoch 2/3\n",
            "48000/48000 [==============================] - 107s 2ms/step - loss: 0.3499 - accuracy: 0.8755 - val_loss: 0.3897 - val_accuracy: 0.8677\n",
            "Epoch 3/3\n",
            "48000/48000 [==============================] - 105s 2ms/step - loss: 0.2942 - accuracy: 0.8951 - val_loss: 0.4135 - val_accuracy: 0.8673\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.callbacks.History at 0x7f16259deb38>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3jWK9kel5aZB",
        "colab_type": "code",
        "outputId": "ac068fa0-c2cd-4d5c-be3e-1c35fd4df8d8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# Evaluate the model on separate test data\n",
        "model1.evaluate(test_images, test_labels, batch_size=10)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 4s 391us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.44537265579076485, 0.8616999983787537]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pgrNWVJC3KAG",
        "colab_type": "text"
      },
      "source": [
        "**Add strides to a convolutional network**\n",
        "\n",
        "The size of the strides of the convolution kernel determines whether the kernel will skip over some of the pixels as it slides along the image. This affects the size of the output because when strides are larger than one, the kernel will be centered on only some of the pixels."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DTNHe-Co3Ozf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Initialize the model\n",
        "model2 = Sequential()\n",
        "\n",
        "# Add the convolutional layer\n",
        "model2.add(Conv2D(100, kernel_size=3, activation='relu', \n",
        "              input_shape=(28, 28, 1), \n",
        "              strides=2))\n",
        "\n",
        "# Feed into output layer\n",
        "model2.add(Flatten())\n",
        "model2.add(Dense(10, activation='softmax'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CjcpspHr5Vwp",
        "colab_type": "code",
        "outputId": "15e85b57-cfeb-49e3-842a-624d757bea15",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "# Compile the model \n",
        "model2.compile(optimizer='adam', \n",
        "              loss='categorical_crossentropy', \n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Fit the model on a training set\n",
        "model2.fit(train_images, train_labels, \n",
        "          validation_split=0.2, \n",
        "          epochs=3, batch_size=10)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 48000 samples, validate on 12000 samples\n",
            "Epoch 1/3\n",
            "48000/48000 [==============================] - 35s 723us/step - loss: 0.6605 - accuracy: 0.8299 - val_loss: 0.4192 - val_accuracy: 0.8487\n",
            "Epoch 2/3\n",
            "48000/48000 [==============================] - 34s 707us/step - loss: 0.3934 - accuracy: 0.8592 - val_loss: 0.4354 - val_accuracy: 0.8523\n",
            "Epoch 3/3\n",
            "48000/48000 [==============================] - 35s 730us/step - loss: 0.3599 - accuracy: 0.8718 - val_loss: 0.4663 - val_accuracy: 0.8420\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.callbacks.History at 0x7f1625a770b8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FLV8LxZS5cLP",
        "colab_type": "code",
        "outputId": "7073ce4f-8337-4ed3-8a7d-f32c33b1e103",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# Evaluate the model on separate test data\n",
        "model2.evaluate(test_images, test_labels, batch_size=10)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 1s 140us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.5018308050846682, 0.8306000232696533]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rg_5RFsb44Qk",
        "colab_type": "text"
      },
      "source": [
        "![alt text](https://raw.githubusercontent.com/raj-vijay/dl/master/images/Output%20Calculation.jpg)"
      ]
    }
  ]
}