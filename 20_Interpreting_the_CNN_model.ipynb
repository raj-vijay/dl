{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "20. Interpreting the CNN model.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOvJx5uoctFdMHVuP81AGD1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/raj-vijay/dl/blob/master/20_Interpreting_the_CNN_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XiX_hXTh-DAl",
        "colab_type": "text"
      },
      "source": [
        "**Save and load machine learning models**\n",
        "\n",
        "Model progress can be saved during—and after—training. Models can also be resumed from where it was left off and avoid long training times. \n",
        "\n",
        "Saving models also help to share the models, so that others can recreate the work. \n",
        "\n",
        "When publishing research models and techniques, most machine learning practitioners share:\n",
        "\n",
        "- code to create the model, and\n",
        "- the trained weights, or parameters, for the model\n",
        "\n",
        "Sharing this data helps others understand how the model works and helps to try the model with new data.\n",
        "\n",
        "However, one need to have caution when dealing with untrusted code — TensorFlow models are code, and hence it is recommended to adopt TensorFlow Security best practices.\n",
        "\n",
        "Source: www.tensorflow.org"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l-SWbe6V99Wh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "e657c506-577a-420d-e37d-2b2c7fbc20fc"
      },
      "source": [
        "!pip install pyyaml h5py  # Required to save models in HDF5 format"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (3.13)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (2.10.0)\n",
            "Requirement already satisfied: numpy>=1.7 in /usr/local/lib/python3.6/dist-packages (from h5py) (1.18.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from h5py) (1.12.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QTyK-diFJtBa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import fundamental libraries used for the tensorflow\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "\n",
        "import os\n",
        "import h5py"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0CD2Yc08KgPM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "c090738a-7b27-4ffa-bc14-d956b3af92a5"
      },
      "source": [
        "# Load the Fashion MNIST Data from TensorFlow Keras\n",
        "fashion_mnist = tf.keras.datasets.fashion_mnist\n",
        "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "32768/29515 [=================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26427392/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "8192/5148 [===============================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4423680/4422102 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "02aSFg43LVRz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "4dc048a7-f477-49e1-ab28-88f320c0b8a0"
      },
      "source": [
        "# Shape of data\n",
        "print(\"Train Images: \", train_images.shape)\n",
        "print(\"Test Images: \", test_images.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train Images:  (60000, 28, 28)\n",
            "Test Images:  (10000, 28, 28)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MZkrm9kryYId",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "9baaaa01-ddb0-45c6-e5fd-041693d15292"
      },
      "source": [
        "# Reshape input data from (28, 28) to (28, 28, 1)\n",
        "w, h = 28, 28\n",
        "train_images = train_images.reshape(train_images.shape[0], w, h, 1)\n",
        "test_images = test_images.reshape(test_images.shape[0], w, h, 1)\n",
        "\n",
        "# One-hot encode the labels\n",
        "train_labels = tf.keras.utils.to_categorical(train_labels, 10)\n",
        "test_labels = tf.keras.utils.to_categorical(test_labels, 10)\n",
        "\n",
        "# Shape of data\n",
        "print(\"Reshaped Train Images: \", train_images.shape)\n",
        "print(\"Reshaped Test Images: \", test_images.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reshaped Train Images:  (60000, 28, 28, 1)\n",
            "Reshaped Test Images:  (10000, 28, 28, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ZZjnqmauxyL",
        "colab_type": "text"
      },
      "source": [
        "**Keras pooling layers**\n",
        "\n",
        "Keras implements a pooling operation as a layer that can be added to CNNs between other layers. \n",
        "\n",
        "- Convolution => Convolution => Flatten => Dense\n",
        "\n",
        "The architecture will add a single max-pooling layer between the convolutional layer and the dense layer with a pooling of 2x2:\n",
        "\n",
        "- Convolution => Max pooling => Convolution => Flatten => Dense"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p3lJ5DmavW0D",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "outputId": "aea55672-4093-4b50-c7a0-46871e7b91c8"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Conv2D, Flatten, MaxPool2D\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "# Add a convolutional layer\n",
        "model.add(Conv2D(100, kernel_size=2, activation='relu', \n",
        "                 input_shape=(28, 28, 1)))\n",
        "\n",
        "# Add a pooling operation\n",
        "model.add(MaxPool2D(2))\n",
        "\n",
        "# Add another convolutional layer\n",
        "model.add(Conv2D(50, kernel_size=2, activation='relu',\n",
        "input_shape=(28, 28, 1)))\n",
        "\n",
        "# Flatten and feed to output layer\n",
        "model.add(Flatten())\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_1 (Conv2D)            (None, 27, 27, 100)       500       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 13, 13, 100)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 12, 12, 50)        20050     \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 7200)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 10)                72010     \n",
            "=================================================================\n",
            "Total params: 92,560\n",
            "Trainable params: 92,560\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Bb4jCYcwKp-",
        "colab_type": "text"
      },
      "source": [
        "**Train a deep CNN with pooling to classify images**\n",
        "\n",
        "Training a CNN with pooling layers is very similar to training of the deep networks. \n",
        "\n",
        "Once the network is constructed, the model needs to be appropriately compiled, and then training data needs to be provided, together with the other arguments that control the fitting procedure."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-cX4ettFZmG4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Compile the model \n",
        "model.compile(optimizer='adam', \n",
        "              loss='categorical_crossentropy', \n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dW22XJHB_Ncl",
        "colab_type": "text"
      },
      "source": [
        "**Save checkpoints during training**\n",
        "\n",
        "It is possible to use a trained model without having to retrain it, or pick-up training from where it was left off—in case the training process was interrupted. \n",
        "\n",
        "The tf.keras.callbacks.ModelCheckpoint callback allows to continually save the model both during and at the end of training.\n",
        "\n",
        "**Checkpoint callback usage**\n",
        "\n",
        "Create a tf.keras.callbacks.ModelCheckpoint callback that saves weights only during training:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cXUdql1d_F9o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "checkpoint_path = \"/content/Results\"\n",
        "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
        "\n",
        "# Create a callback that saves the model's weights every 5 epochs\n",
        "cp_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_path, \n",
        "    verbose=1, \n",
        "    save_weights_only=True,\n",
        "    save_freq=5)\n",
        "\n",
        "# Save the weights using the `checkpoint_path` format\n",
        "model.save_weights(checkpoint_path.format(epoch=0))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G0WeKK0sv9CJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "0eb6af84-22c0-49ae-b73b-13f18241be94"
      },
      "source": [
        "# Fit the model to training data \n",
        "model.fit(train_images, train_labels, validation_split=0.2, epochs=3, batch_size=10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 48000 samples, validate on 12000 samples\n",
            "Epoch 1/3\n",
            "48000/48000 [==============================] - 84s 2ms/step - loss: 0.2432 - accuracy: 0.9117 - val_loss: 0.3301 - val_accuracy: 0.8904\n",
            "Epoch 2/3\n",
            "48000/48000 [==============================] - 83s 2ms/step - loss: 0.2396 - accuracy: 0.9115 - val_loss: 0.3336 - val_accuracy: 0.8866\n",
            "Epoch 3/3\n",
            "48000/48000 [==============================] - 83s 2ms/step - loss: 0.2313 - accuracy: 0.9140 - val_loss: 0.3495 - val_accuracy: 0.8817\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.callbacks.History at 0x7f530f4b08d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LqFCDDzCBRXL",
        "colab_type": "text"
      },
      "source": [
        "A single collection of TensorFlow checkpoint files are created and updated at the end of each epoch."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qAo3GLovBaba",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "77920144-a113-4956-91b1-c937e0ca5bde"
      },
      "source": [
        "!ls {checkpoint_dir}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Results  sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PW5A0UpXNrII",
        "colab_type": "text"
      },
      "source": [
        "**Plot the learning curves**\n",
        "\n",
        "During learning, the model will store the loss function evaluated in each epoch. Looking at the learning curves can tell us quite a bit about the learning process."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9rtNL8aR9JpR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 404
        },
        "outputId": "a37d190c-bc06-462e-b7da-b08b602915dd"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Train the model and store the training object\n",
        "training = model.fit(train_images, train_labels,\n",
        "epochs=3, batch_size = 10, validation_split=0.2)\n",
        "\n",
        "# Extract the history from the training object\n",
        "history = training.history\n",
        "\n",
        "# Plot the training loss \n",
        "plt.plot(history['loss'])\n",
        "# Plot the validation loss\n",
        "plt.plot(history['val_loss'])\n",
        "\n",
        "# Show the figure\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 48000 samples, validate on 12000 samples\n",
            "Epoch 1/3\n",
            "48000/48000 [==============================] - 80s 2ms/step - loss: 0.2923 - accuracy: 0.8930 - val_loss: 0.3220 - val_accuracy: 0.8882\n",
            "Epoch 2/3\n",
            "48000/48000 [==============================] - 80s 2ms/step - loss: 0.2773 - accuracy: 0.8980 - val_loss: 0.3315 - val_accuracy: 0.8852\n",
            "Epoch 3/3\n",
            "48000/48000 [==============================] - 80s 2ms/step - loss: 0.2644 - accuracy: 0.9015 - val_loss: 0.3291 - val_accuracy: 0.8892\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2m57eNEK0CBM",
        "colab_type": "text"
      },
      "source": [
        "**Evaluating a CNN with test data**\n",
        "\n",
        "To evaluate a trained neural network, provide a separate testing data set of labeled images."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UK_GCeW-0Il3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "bc42a7c5-9319-4b6f-e928-66860229348c"
      },
      "source": [
        "# Evaluate the model on separate test data\n",
        "model.evaluate(test_images, test_labels, batch_size=10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 5s 471us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.3801005983844516, 0.8734999895095825]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BxiY939n84j2",
        "colab_type": "text"
      },
      "source": [
        "**Extracting a kernel from a trained network**\n",
        "\n",
        "One way to interpret models is to examine the properties of the kernels in the convolutional layers. \n",
        "\n",
        "Here we extract one of the kernels from a convolutional neural network with weights saved in a hdf5 file."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "80nuvEhjDbUm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "6332bd62-7565-4751-e852-57dfe61de101"
      },
      "source": [
        "import sys\n",
        "print(sys.path)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['', '/env/python', '/usr/lib/python36.zip', '/usr/lib/python3.6', '/usr/lib/python3.6/lib-dynload', '/usr/local/lib/python3.6/dist-packages', '/usr/lib/python3/dist-packages', '/usr/local/lib/python3.6/dist-packages/IPython/extensions', '/root/.ipython']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J3qyhGmVEHGk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "7b1639b5-b836-4d11-d823-a3e1461c61ac"
      },
      "source": [
        "import os, fnmatch\n",
        "def find(pattern, path):\n",
        "    result = []\n",
        "    for root, dirs, files in os.walk(path):\n",
        "        for name in files:\n",
        "            if fnmatch.fnmatch(name, pattern):\n",
        "                result.append(os.path.join(root, name))\n",
        "    return result\n",
        "\n",
        "find('*.hdf5', '/')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/usr/local/lib/python3.6/dist-packages/astropy/io/misc/tests/data/old_meta_example.hdf5',\n",
              " '/usr/local/lib/python3.6/dist-packages/textgenrnn/textgenrnn_weights.hdf5']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PbW2vSi29HO8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 476
        },
        "outputId": "4f450496-cb89-4e1e-80e0-368f25bfc6ff"
      },
      "source": [
        "# Load the weights into the model\n",
        "model.load_weights('weights.hdf5')\n",
        "\n",
        "# Get the first convolutional layer from the model\n",
        "c1 = model.layers[0]\n",
        "\n",
        "# Get the weights of the first convolutional layer\n",
        "weights1 = c1.get_weights()\n",
        "\n",
        "# Pull out the first channel of the first kernel in the first layer\n",
        "kernel = weights1[0][...,0, 0]\n",
        "print(kernel)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "OSError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-37-5ead6b585c90>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'weights.hdf5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Get the first convolutional layer from the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mc1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/saving.py\u001b[0m in \u001b[0;36mload_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    490\u001b[0m                 \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmp_filepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 492\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mload_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    493\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mload_wrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/network.py\u001b[0m in \u001b[0;36mload_weights\u001b[0;34m(self, filepath, by_name, skip_mismatch, reshape)\u001b[0m\n\u001b[1;32m   1219\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mh5py\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1220\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'`load_weights` requires h5py.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1221\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mh5py\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1222\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;34m'layer_names'\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattrs\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m'model_weights'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1223\u001b[0m                 \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'model_weights'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, **kwds)\u001b[0m\n\u001b[1;32m    406\u001b[0m                 fid = make_fid(name, mode, userblock_size,\n\u001b[1;32m    407\u001b[0m                                \u001b[0mfapl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfcpl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmake_fcpl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrack_order\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrack_order\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 408\u001b[0;31m                                swmr=swmr)\n\u001b[0m\u001b[1;32m    409\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    410\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlibver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36mmake_fid\u001b[0;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[1;32m    171\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mswmr\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m             \u001b[0mflags\u001b[0m \u001b[0;34m|=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_SWMR_READ\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    174\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'r+'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_RDWR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mh5py/h5f.pyx\u001b[0m in \u001b[0;36mh5py.h5f.open\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mOSError\u001b[0m: Unable to open file (unable to open file: name = 'weights.hdf5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)"
          ]
        }
      ]
    }
  ]
}